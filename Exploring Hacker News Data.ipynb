{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "# Exploring Hackers News Posts\n",
    "\n",
    "In this project, we'll compare two different types of posts from Hacker News, a popular site where technology related stories (or 'posts') are voted and commented upon. The two types of posts we'll explore begin with either Ask HN or Show HN.\n",
    "\n",
    "Users submit Ask HN posts to ask the Hacker News community a specific question, such as \"What is the best online course you've ever taken?\" Likewise, users submit Show HN posts to show the Hacker News community a project, product, or just generally something interesting.\n",
    "\n",
    "We'll specifically compare these two types of posts to determine the following:\n",
    "\n",
    "Do Ask HN or Show HN receive more comments on average?\n",
    "Do posts created at a certain time receive more comments on average?\n",
    "It should be noted that the data set we're working with was reduced from almost 300,000 rows to approximately 20,000 rows by removing all submissions that did not receive any comments, and then randomly sampling from the remaining submissions.\n",
    "\n",
    "_Topic Sentence from Dataquest"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Analysing Hacker News dataset to answer two Main Questions:\n",
    "1)Do Ask HN or Show HN receive more comments on average?\n",
    "2)Do posts created at a certain time receive more comments on average?\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Importing Reader module from CSV Package and displaying first 5 rows of data for sanity check."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[['id', 'title', 'url', 'num_points', 'num_comments', 'author', 'created_at'], ['12224879', 'Interactive Dynamic Video', 'http://www.interactivedynamicvideo.com/', '386', '52', 'ne0phyte', '8/4/2016 11:52'], ['10975351', 'How to Use Open Source and Shut the Fuck Up at the Same Time', 'http://hueniverse.com/2016/01/26/how-to-use-open-source-and-shut-the-fuck-up-at-the-same-time/', '39', '10', 'josep2', '1/26/2016 19:30'], ['11964716', \"Florida DJs May Face Felony for April Fools' Water Joke\", 'http://www.thewire.com/entertainment/2013/04/florida-djs-april-fools-water-joke/63798/', '2', '1', 'vezycash', '6/23/2016 22:20'], ['11919867', 'Technology ventures: From Idea to Enterprise', 'https://www.amazon.com/Technology-Ventures-Enterprise-Thomas-Byers/dp/0073523429', '3', '1', 'hswarna', '6/17/2016 0:01']]\n"
     ]
    }
   ],
   "source": [
    "from csv import reader\n",
    "\n",
    "### The Hacker News data set ###\n",
    "opened_file = open('hacker_news.csv')\n",
    "read_file = reader(opened_file)\n",
    "hn = list(read_file)\n",
    "\n",
    "print(hn[:5])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Sample extract shows that the first row displays headers. Amending hn output to remove Header column from analysis.\n",
    "\n",
    "Extract headers row and print headers variable to check it.\n",
    "Print modified hn output."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[['id', 'title', 'url', 'num_points', 'num_comments', 'author', 'created_at']]\n"
     ]
    }
   ],
   "source": [
    "headers = hn[:1]\n",
    "print(headers)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[['12224879', 'Interactive Dynamic Video', 'http://www.interactivedynamicvideo.com/', '386', '52', 'ne0phyte', '8/4/2016 11:52'], ['10975351', 'How to Use Open Source and Shut the Fuck Up at the Same Time', 'http://hueniverse.com/2016/01/26/how-to-use-open-source-and-shut-the-fuck-up-at-the-same-time/', '39', '10', 'josep2', '1/26/2016 19:30'], ['11964716', \"Florida DJs May Face Felony for April Fools' Water Joke\", 'http://www.thewire.com/entertainment/2013/04/florida-djs-april-fools-water-joke/63798/', '2', '1', 'vezycash', '6/23/2016 22:20'], ['11919867', 'Technology ventures: From Idea to Enterprise', 'https://www.amazon.com/Technology-Ventures-Enterprise-Thomas-Byers/dp/0073523429', '3', '1', 'hswarna', '6/17/2016 0:01'], ['10301696', 'Note by Note: The Making of Steinway L1037 (2007)', 'http://www.nytimes.com/2007/11/07/movies/07stein.html?_r=0', '8', '2', 'walterbell', '9/30/2015 4:12']]\n"
     ]
    }
   ],
   "source": [
    "hn = hn[1:]\n",
    "print(hn[:5])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As we are only concerned with posts  \"Ask HN\" and \"Show HN\", we search for post titles that begin with the above two strings and will build new lists to classify them, as well as a catch all for other posts. Ask these identifiers are at the start of the post, we can make use of the startswith method to identify these posts. \n",
    "\n",
    "_(To check later if there is something else to use if the string is in the middle of a string, such as Contains function in SAS)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1744\n",
      "1162\n",
      "17194\n"
     ]
    }
   ],
   "source": [
    "ask_posts = []\n",
    "show_posts =[]\n",
    "other_posts =[]\n",
    "\n",
    "for row in hn:\n",
    "    title = row[1]\n",
    "    if title.lower().startswith(\"ask hn\"):\n",
    "        ask_posts.append(row)\n",
    "    elif title.lower().startswith(\"show hn\"):\n",
    "        show_posts.append(row)\n",
    "    else:\n",
    "        other_posts.append(row)\n",
    "\n",
    "print(len(ask_posts))\n",
    "print(len(show_posts))\n",
    "print(len(other_posts))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Print length of each lists and the first 5 rows for sanity check."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[['12296411', 'Ask HN: How to improve my personal website?', '', '2', '6', 'ahmedbaracat', '8/16/2016 9:55'], ['10610020', 'Ask HN: Am I the only one outraged by Twitter shutting down share counts?', '', '28', '29', 'tkfx', '11/22/2015 13:43'], ['11610310', 'Ask HN: Aby recent changes to CSS that broke mobile?', '', '1', '1', 'polskibus', '5/2/2016 10:14'], ['12210105', 'Ask HN: Looking for Employee #3 How do I do it?', '', '1', '3', 'sph130', '8/2/2016 14:20']]\n",
      "[['10627194', 'Show HN: Wio Link  ESP8266 Based Web of Things Hardware Development Platform', 'https://iot.seeed.cc', '26', '22', 'kfihihc', '11/25/2015 14:03'], ['10646440', 'Show HN: Something pointless I made', 'http://dn.ht/picklecat/', '747', '102', 'dhotson', '11/29/2015 22:46'], ['11590768', 'Show HN: Shanhu.io, a programming playground powered by e8vm', 'https://shanhu.io', '1', '1', 'h8liu', '4/28/2016 18:05'], ['12178806', 'Show HN: Webscope  Easy way for web developers to communicate with Clients', 'http://webscopeapp.com', '3', '3', 'fastbrick', '7/28/2016 7:11']]\n",
      "[['12224879', 'Interactive Dynamic Video', 'http://www.interactivedynamicvideo.com/', '386', '52', 'ne0phyte', '8/4/2016 11:52'], ['10975351', 'How to Use Open Source and Shut the Fuck Up at the Same Time', 'http://hueniverse.com/2016/01/26/how-to-use-open-source-and-shut-the-fuck-up-at-the-same-time/', '39', '10', 'josep2', '1/26/2016 19:30'], ['11964716', \"Florida DJs May Face Felony for April Fools' Water Joke\", 'http://www.thewire.com/entertainment/2013/04/florida-djs-april-fools-water-joke/63798/', '2', '1', 'vezycash', '6/23/2016 22:20'], ['11919867', 'Technology ventures: From Idea to Enterprise', 'https://www.amazon.com/Technology-Ventures-Enterprise-Thomas-Byers/dp/0073523429', '3', '1', 'hswarna', '6/17/2016 0:01']]\n"
     ]
    }
   ],
   "source": [
    "print(ask_posts[:4])\n",
    "print(show_posts[:4])\n",
    "print(other_posts[:4])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Create variables to count and store the Total and Average count of comments in each list."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "14.038417431192661\n"
     ]
    }
   ],
   "source": [
    "total_ask_comments = 0\n",
    "for row in ask_posts:\n",
    "    total_ask_comments += int(row[4])\n",
    "    \n",
    "avg_ask_comments = total_ask_comments/ len(ask_posts)\n",
    "print(avg_ask_comments)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10.31669535283993\n"
     ]
    }
   ],
   "source": [
    "total_show_comments = 0\n",
    "for row in show_posts:\n",
    "    total_show_comments += int(row[4])\n",
    "    \n",
    "avg_show_comments = total_show_comments/ len(show_posts)\n",
    "print(avg_show_comments)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "On average, Ask HN posts at 14.038 have more comments than Show HN posts at 10.317. This answers our first question above."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Moving on to the second question, we begin by importing the datetime module to allow us to analyse the number of comments per hour.\n",
    "\n",
    "We will build 2 dictionaries to store the counts per hour, as well as the comments per hour and use these to answer the second question."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import datetime as dt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'05': 464, '12': 687, '10': 793, '14': 1416, '23': 543, '01': 683, '02': 1381, '08': 492, '09': 251, '04': 337, '17': 1146, '15': 4477, '11': 641, '18': 1439, '07': 267, '13': 1253, '19': 1188, '22': 479, '20': 1722, '21': 1745, '00': 447, '16': 1814, '03': 421, '06': 397}\n",
      "{'05': 46, '12': 73, '10': 59, '14': 107, '23': 68, '01': 60, '02': 58, '08': 48, '09': 45, '04': 47, '17': 100, '15': 116, '11': 58, '18': 109, '07': 34, '13': 85, '19': 110, '22': 71, '20': 80, '21': 109, '00': 55, '16': 108, '03': 54, '06': 44}\n"
     ]
    }
   ],
   "source": [
    "result_list =[]\n",
    "for row in ask_posts:\n",
    "    result_list.append(\n",
    "        [row[6],int(row[4])]\n",
    "    )\n",
    "\n",
    "counts_by_hour = {}\n",
    "comments_by_hour = {}\n",
    "date_format = \"%m/%d/%Y %H:%M\"\n",
    "\n",
    "for row in result_list:\n",
    "    date = row[0]\n",
    "    comment = row[1]\n",
    "    time = dt.datetime.strptime(date,date_format).strftime(\"%H\")\n",
    "    if time in counts_by_hour:\n",
    "        comments_by_hour[time] +=comment\n",
    "        counts_by_hour[time] +=1\n",
    "    else:\n",
    "        comments_by_hour[time] =comment\n",
    "        counts_by_hour[time] =1\n",
    "        \n",
    "print(comments_by_hour)\n",
    "\n",
    "print(counts_by_hour)\n",
    "         "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next, we use the two dictionaries to calculate the average number of posts per hour interval."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[['05', 10.08695652173913], ['12', 9.41095890410959], ['10', 13.440677966101696], ['14', 13.233644859813085], ['23', 7.985294117647059], ['01', 11.383333333333333], ['02', 23.810344827586206], ['08', 10.25], ['09', 5.5777777777777775], ['04', 7.170212765957447], ['17', 11.46], ['15', 38.5948275862069], ['11', 11.051724137931034], ['18', 13.20183486238532], ['07', 7.852941176470588], ['13', 14.741176470588234], ['19', 10.8], ['22', 6.746478873239437], ['20', 21.525], ['21', 16.009174311926607], ['00', 8.127272727272727], ['16', 16.796296296296298], ['03', 7.796296296296297], ['06', 9.022727272727273]]\n"
     ]
    }
   ],
   "source": [
    "avg_by_hour = []\n",
    "for hour in comments_by_hour:\n",
    "    avg_by_hour.append([hour,comments_by_hour[hour]/counts_by_hour[hour]]\n",
    "    )\n",
    "    \n",
    "print(avg_by_hour)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The output data is still in a mess and hard to interpret/use. We need to sort the data in the list and transform the data. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[10.08695652173913, '05'], [9.41095890410959, '12'], [13.440677966101696, '10'], [13.233644859813085, '14'], [7.985294117647059, '23'], [11.383333333333333, '01'], [23.810344827586206, '02'], [10.25, '08'], [5.5777777777777775, '09'], [7.170212765957447, '04'], [11.46, '17'], [38.5948275862069, '15'], [11.051724137931034, '11'], [13.20183486238532, '18'], [7.852941176470588, '07'], [14.741176470588234, '13'], [10.8, '19'], [6.746478873239437, '22'], [21.525, '20'], [16.009174311926607, '21'], [8.127272727272727, '00'], [16.796296296296298, '16'], [7.796296296296297, '03'], [9.022727272727273, '06']]\n"
     ]
    }
   ],
   "source": [
    "swap_avg_by_hour = []\n",
    "for hour in avg_by_hour:\n",
    "    swap_avg_by_hour.append(\n",
    "        [hour[1],hour[0]]\n",
    "    )\n",
    "print(swap_avg_by_hour)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[38.5948275862069, '15'], [23.810344827586206, '02'], [21.525, '20'], [16.796296296296298, '16'], [16.009174311926607, '21'], [14.741176470588234, '13'], [13.440677966101696, '10'], [13.233644859813085, '14'], [13.20183486238532, '18'], [11.46, '17'], [11.383333333333333, '01'], [11.051724137931034, '11'], [10.8, '19'], [10.25, '08'], [10.08695652173913, '05'], [9.41095890410959, '12'], [9.022727272727273, '06'], [8.127272727272727, '00'], [7.985294117647059, '23'], [7.852941176470588, '07'], [7.796296296296297, '03'], [7.170212765957447, '04'], [6.746478873239437, '22'], [5.5777777777777775, '09']]\n"
     ]
    }
   ],
   "source": [
    "sorted_swap = sorted(swap_avg_by_hour,reverse=True)\n",
    "print(sorted_swap)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Top 5 Hours for Ask Posts Comments\n",
      "15:00: 38.59 average comments per post\n",
      "02:00: 23.81 average comments per post\n",
      "20:00: 21.52 average comments per post\n",
      "16:00: 16.80 average comments per post\n",
      "21:00: 16.01 average comments per post\n"
     ]
    }
   ],
   "source": [
    "print(\"Top 5 Hours for Ask Posts Comments\")\n",
    "for avg, hour in sorted_swap[:5]:\n",
    "    print(\n",
    "    \"{}: {:.2f} average comments per post\".format(\n",
    "        dt.datetime.strptime(hour, \"%H\").strftime(\"%H:%M\"),avg\n",
    "        )\n",
    "    )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Referencing back to our 2 main questions above:\n",
    "\n",
    "1) Do Ask HN or Show HN receive more comments on average?\n",
    "\n",
    "2) Do posts created at a certain time receive more comments on average?\n",
    "\n",
    "Ans:\n",
    "1) Ask HN posts receive more comments on average at 14 approx as compared to Show HN at 10 approx.\n",
    "\n",
    "2) There is a clear distinction between the timings that have the the higher number of average comments per posts.\n",
    "\n",
    "In order to receive the most number of comments on your post, you should make a post at 15:00. However, it is pertinent to note that we excluded posts without any comments from our analysis. Thus, our results may be slightly skewed as the count is not 100% accurately. However, it is likely that removing these posts with 0 comments would result in more meaningful results as this filter could remove noise such as spam posts."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
